{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DogCat.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeerthikaReddy02/Phobia-Detector/blob/main/DogCat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfO1CpTEhtJQ"
      },
      "source": [
        "#Dog cat prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mcs_Js9QK0-W"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rJ86BbMh5ON"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZpSl_60i4_H"
      },
      "source": [
        "##Data pre processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAEFDWo9i_Wi",
        "outputId": "5c4a0815-6e2a-4b15-aa2d-110f91a72007"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWsAPpZzjG6v",
        "outputId": "7f661c0f-48e7-4a43-c07d-bed66ddb03e3"
      },
      "source": [
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U82qhC5flFEQ"
      },
      "source": [
        "##Building CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-O9koZelHTh"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0kYCqWcmsY7"
      },
      "source": [
        "##Training the CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RVRXQckwpbt"
      },
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1eC5_UOKqKc",
        "outputId": "f50788ed-da6e-4027-8a9c-c39617d94094"
      },
      "source": [
        "cnn.fit(x=training_set,validation_data=test_set,epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 143s 571ms/step - loss: 0.6623 - accuracy: 0.6045 - val_loss: 0.6120 - val_accuracy: 0.6725\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 76s 306ms/step - loss: 0.6243 - accuracy: 0.6541 - val_loss: 0.6070 - val_accuracy: 0.6680\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 77s 308ms/step - loss: 0.5871 - accuracy: 0.6869 - val_loss: 0.5941 - val_accuracy: 0.6900\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 80s 320ms/step - loss: 0.5554 - accuracy: 0.7266 - val_loss: 0.5894 - val_accuracy: 0.7055\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 80s 321ms/step - loss: 0.5395 - accuracy: 0.7303 - val_loss: 0.5926 - val_accuracy: 0.6865\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 100s 400ms/step - loss: 0.5137 - accuracy: 0.7439 - val_loss: 0.5012 - val_accuracy: 0.7710\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 92s 368ms/step - loss: 0.4884 - accuracy: 0.7594 - val_loss: 0.5271 - val_accuracy: 0.7270\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 79s 316ms/step - loss: 0.4792 - accuracy: 0.7740 - val_loss: 0.5233 - val_accuracy: 0.7565\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 86s 342ms/step - loss: 0.4513 - accuracy: 0.7837 - val_loss: 0.4724 - val_accuracy: 0.7820\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 102s 410ms/step - loss: 0.4398 - accuracy: 0.7922 - val_loss: 0.4738 - val_accuracy: 0.7840\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 131s 524ms/step - loss: 0.4250 - accuracy: 0.8001 - val_loss: 0.4676 - val_accuracy: 0.7985\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 118s 474ms/step - loss: 0.4109 - accuracy: 0.8121 - val_loss: 0.5050 - val_accuracy: 0.7630\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 79s 317ms/step - loss: 0.3948 - accuracy: 0.8251 - val_loss: 0.4922 - val_accuracy: 0.7830\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 66s 265ms/step - loss: 0.3818 - accuracy: 0.8253 - val_loss: 0.4749 - val_accuracy: 0.7965\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 64s 255ms/step - loss: 0.3645 - accuracy: 0.8381 - val_loss: 0.4719 - val_accuracy: 0.7935\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 66s 265ms/step - loss: 0.3459 - accuracy: 0.8438 - val_loss: 0.5042 - val_accuracy: 0.7930\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 66s 263ms/step - loss: 0.3223 - accuracy: 0.8572 - val_loss: 0.5245 - val_accuracy: 0.7920\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 66s 264ms/step - loss: 0.3133 - accuracy: 0.8662 - val_loss: 0.5438 - val_accuracy: 0.7830\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 78s 314ms/step - loss: 0.3075 - accuracy: 0.8616 - val_loss: 0.5106 - val_accuracy: 0.7995\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 83s 332ms/step - loss: 0.2879 - accuracy: 0.8761 - val_loss: 0.5276 - val_accuracy: 0.7995\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 78s 311ms/step - loss: 0.2712 - accuracy: 0.8899 - val_loss: 0.5112 - val_accuracy: 0.7925\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 104s 415ms/step - loss: 0.2513 - accuracy: 0.8936 - val_loss: 0.5497 - val_accuracy: 0.7960\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 132s 527ms/step - loss: 0.2414 - accuracy: 0.9031 - val_loss: 0.6167 - val_accuracy: 0.7680\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 143s 571ms/step - loss: 0.2276 - accuracy: 0.9085 - val_loss: 0.5544 - val_accuracy: 0.7840\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 124s 494ms/step - loss: 0.2183 - accuracy: 0.9107 - val_loss: 0.6096 - val_accuracy: 0.7945\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2274c2a8d60>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8g2ZQrdLTaN"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFuxHywKKqKc",
        "outputId": "860110fa-9c02-4db5-a37b-a919e7721346"
      },
      "source": [
        "cnn.save(\"dogcat.h5\")\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        }
      ]
    }
  ]
}